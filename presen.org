#+title: 
#+author: 
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+LINK: ssvg file:img/static/%s.svg
#+LINK: sgif file:img/static/%s.gif

#+begin_outline-text-1
#+begin_center
Talk with Patrick Cooper
#+end_center
#+end_outline-text-1

* My background

+ Symbolic AI
  + Automated Planning and Scheduling
  + Decision making, Knowledge Representation, Graph Search, Optimization
  + *Sound and explainable AIs*
    + Applications: Autonomous Satellite Operation, Logistics, Manufacturing
      + We cannot allow AI to make mistakes in Space
      + because we cannot afford *destroying the spaceships!*
      + Been deployed in many mission-critical applications
+ I have multiple papers in Top-Tier AI confs/journals: AAAI(1), IJCAI(1), ICAPS(3), JAIR(1)

* 

#+begin_xlarge
#+begin_center
I am from */Planning/* community
#+end_center
#+end_xlarge

#+begin_center
[[sgif:icapslogo]]

International Conference on Automated Planning and Scheduling

(AAAI sister conference, 33% avg. accept ratio, since 1990, ECP+AIPSâ†’ICAPS)
#+end_center

https://en.wikipedia.org/wiki/Automated_planning_and_scheduling

http://portal.core.edu.au/conf-ranks/919/ A* ratings (same as AAAI, NIPS, ICML)

* My most recent work

*Classical Planning in Deep Latent Space: From Unlabelled Images to PDDL (and Back)*

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+ The first and successful attempt to generate the symbolic input for Classical Planner directly from images

+ Generate symbols using Variational AutoEncoder w/ gumbel-softmax (ICLR17)

+ Then solve the symbolic planning problem

+ Map the results back to images
#+end_span6
#+begin_span6
[[png:results/mnist-plan]]
#+end_span6
#+end_row-fluid
#+end_container-fluid

+ Been through reviewed workshops (KEPS17 in ICAPS, NeSy17, Cognitum17 in IJCAI)

* Quotes

#+begin_quote
+ Scott Sanner (U Toronto, ICAPS Executive Council) :: If I reviewed this paper, I would nomitate it for the best paper.

+ Rao Kambhampati (ASU, AAAI President) :: We need more papers combining DL and planning.
#+end_quote

I presented this work in NeSy17 and it caught attention of Dr. Shanahan @
DeepMind, who seemed to have encouraged someone in charge to pick me up.

* Typical Filters

+ If you see my CV through a typical filter, you miss me

  + No "accredited" Machine Learning papers (ICML, ICLR, NIPS)

+ But I have lots to talk about logics for ML people

  + Large gaps in ML and AI community

    + Despite the public (and wrong) perception: "*/AI is ML, and ML is the AI/*"

  + ML papers rarely cites AI/symbolic papers

    + Personal communication with Subbarao Kambhampati @ ICAPS banquet

* Why you should hire me?

+ Deepmind's current focus is heavily biased on:
  + Reinforcement Learning (DQN)
  + Human-competitive Games (AlphaGo)
+ What's missing in DM's goal for AGI?
+ Domain-independent Deliberative Agent
  + 1: [[https://en.wikipedia.org/wiki/Reactive_planning][DQN / RL is strictly reactive, like Pavlov's dog]]
  + 2: Domain-independent reasoning
  + 3: Single-agent deliberation, not games

* RL is strictly reactive, like Pavlov's dog

+ RL greedily trust the learned Q-function, which may work in Atari games
  + Atari games are reactive, younger players are good at games
+ By design, not capable of reasoning about the long future, may fall in deadend
  + 1-step (Q-learning) or 2-steps (SARSA) future only
  + E.g. An autonomous car may drive around too long, failing to foresee running out of fuel
+ Cannot be used for critical applications, no *theoretical guarantees* for soundness
  + Like space applications, expensive robots, medical applications

* Domain-independnet Reasoning

+ AlphaGo is a Go-specific solver, Human solves various problems
+ Planning provides domain-independent solvers: One solver to rule them all
+ SIGAPS (collection of planning applications) http://users.cecs.anu.edu.au/~patrik/sigaps/index.php

* Single-agent deliberation, not games

+ Where *right* and *optimal* answers matter (completeness & optimality)
  + optimality -> smallest cost
+ Compared to achieving the *optimal* solution, it is easier to win against the human!


* What I can provide

+ Deep understanding of symbolic systems
  + Domain-independent reasononing techniques which ML people are not familiar with
    + Delete-relaxation, Landmarks
    + Abstraction, Critical Path
    + LP-relaxation, cost partitioning
+ What is necessary for symbolic systems
  + Symbols not just for objects: Also for predicates, actions, ...
+ How to use NN for providing such necessity
  + Variational AE compatible with symbolic systems

* The reason I want to join

+ Top-of-the-World research colleague
+ Same vision
  + Deepmind is aiming at Neural-Symbolic hybrid systems
    + Deep Symbolic RL (from Dr. Shanahan)
    + SCAN system 
  + Not many people/institutions realize this importance yet
    + e.g. Business-hungry institutes claiming "We do AI", requiring ML publications

* The reason I want to join (more personal)

+ I chose to be a planning researcher because I am not good at planning
  + Difficulty in organizing, planning, scheduling
+ Planning = logical deliberation, reasoning ahead of time
  + People are bad at logical reasoning, BTW
  + Trump, Trump, Trump
+ Current AI hype: Why Reinforcement Learning?
  + RL is about acting based on reflex and short-term reward.
  + I am a reactive, reflex, impulsive person. I fed up with it and want to change it.
  + We need a better reasoner than human, for human.
    + This is the whole point of AI research.
    + RL does not help in this regard.
+ I would like to disrupt Deepmind in a good way.
  + Planning shares some notion with Game playing
  + Dom-ind planning is way ahead from dom-ind game playing (called GGP^1)
  + I want to influence ML community too.

#+begin_note
^1 General Game Playing
#+end_note
